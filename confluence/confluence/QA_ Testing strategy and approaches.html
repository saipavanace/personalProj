<div class="contentLayout2">
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><style type='text/css'>/*<![CDATA[*/
div.rbtoc1759723697094 {padding: 0px;}
div.rbtoc1759723697094 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1759723697094 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class='toc-macro rbtoc1759723697094'>
<ul class='toc-indentation'>
<li><a href='#QA:Testingstrategyandapproaches-Documentdescription'>Document description</a></li>
<li><a href='#QA:Testingstrategyandapproaches-Definitionsfortestingactivities'>Definitions for testing activities</a></li>
<li><a href='#QA:Testingstrategyandapproaches-Definitionsforqualityassuranceactivities'>Definitions for quality assurance activities</a></li>
<li><a href='#QA:Testingstrategyandapproaches-Testapproachesfortesting'>Test approaches for testing</a></li>
<li><a href='#QA:Testingstrategyandapproaches-Oneofpossiblesolutionstoimprovebuildquality'>One of possible solutions to improve build quality</a></li>
</ul>
</div></p><h2 id="QA:Testingstrategyandapproaches-Documentdescription">Document description</h2><p>The main aim of describing test strategy and approaches is to add transparency of QA team work and needs. Here you can find the main descriptions of used QA definitions and find the answer why we need spend time on it. If there are any questions related to QA process, please contact <a class="confluence-userlink user-mention" data-account-id="624b36bd5f63fd0069b55454" href="https://arterisip.atlassian.net/wiki/people/624b36bd5f63fd0069b55454?ref=confluence" target="_blank" data-base-url="https://arterisip.atlassian.net/wiki">Alesya Goncharik (Deactivated)</a> and / or leave a comment to this document. </p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><br/></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<h2 id="QA:Testingstrategyandapproaches-Definitionsfortestingactivities">Definitions for testing activities</h2><p><strong>DV (Defect Validation)</strong> - the main aim of the activity is to validate bug was fixed or not. Performed by the steps from description.</p><p><strong>NFT (New Feature Testing)</strong> - testing new feature, often includes additional testing activities for old features which is connected to a new one. To validate results during this activity better to use checklists or / and test cases written before. But in our case it could be performed by technical requirements. Without documentation reporting and results could be less accurate.  </p><p><strong>Critical path</strong> - testing the app by main steps which standard user will perform during using the app. For now for these purposes could be used demo flow document, but in the future it should be changed to cover the main functionality. Should be performed before the release / demo. Could be performed sometimes for new builds (if there are special needs or available time for this).  </p><p><strong>Regression</strong> - testing the app by prepared checklists and cases, can't be performed without it. Uses for validating that all main functions of the app works as expected. Performed before major releases. Requires a lot of time (depending on written documentation and available functions of the app). </p><p><strong>Smoke test </strong>- fast check that the app is not crashed on start. In general performed indirectly while the app is used for DV, NFT and Critical path. </p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><br/></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<h2 id="QA:Testingstrategyandapproaches-Definitionsforqualityassuranceactivities">Definitions for quality assurance activities</h2><p><strong>Test documentation creating</strong> - working on available requirements, creating short lists of functions which should be checked. In general should be performed during developing phase when there are available ready requirements for the app but nothing is ready to test. In our case documentation could be written when the feature is in development but not ready yet. For this step is very important to have a 'requirements owner' - the person who knows how exactly new feature should work and can describe all dependencies.  </p><p><strong>Reporting </strong>- short test report which could be created in the end of the sprint which will be contain the important information about the last build quality. On our projects to create useful test report we need to resolve a problem with build version and testing approaches. </p><p><strong>Build status report</strong> - optional report which is created after critical path or / and new feature testing which contains information about passed / failed checks.</p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><br/></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<h2 id="QA:Testingstrategyandapproaches-Testapproachesfortesting">Test approaches for testing</h2><p>In general test approach is based on which development process is used for the app and also which is release strategy is used for. </p><p>In current situation we have only one master brunch that changes constantly every day. Testing activities performed on daily build that includes all code changes for the previous days. But even without any changes we can follow the next strategy: </p><p><strong>Step 1.</strong> Create test documentation and needed requirements for basic functionality. This will be everyday task which should be performed when there are no DV and NFT activities. </p><p><strong>Step 2</strong>. Perform defect validation daily, based on resolved bugs in Jira. Perform NFT for every task which is in resolved state and could be tested from GUI (technical tasks are resolved as soon as they are in the master). New bugs will be created with daily build version to minimize unclear steps to reproduce. </p><p><strong>Step 3</strong>. Before the demo master build should be freezes to provide QA team stable build that can be tested for 1-2 days. </p><p><strong>Risks and problems for the current solution</strong></p><p>Risks mainly connected to unstable build and lack of available documentation to create full checklists. Also in our case there could be problems with development because developers won't be able to push their code to master. One more problem is that situation with daily updated master leads to appearing new crashes which is sometimes are not reproducible on the next builds. Also it takes more time for debugging and testing all previously found issues. New feature testing is also hard to control because there is no precise information how many parts of the feature was already developed. </p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><br/></p></div>
</div>
</div>
<div class="columnLayout single" data-layout="single">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<h2 id="QA:Testingstrategyandapproaches-Oneofpossiblesolutionstoimprovebuildquality">One of possible solutions to improve build quality </h2><p>We can create two different brunches for code. QA brunch is always will be more stable than development and won't be updated daily which helps in testing tasks and defects validation. Also if we will test QA build before the demo, all development process shouldn't be freezes - all commits are still could be pushed to development brunch. After testing the last available QA build was finished successfully the code could be pushed to Master brunch. And could be used for release / demo purposes. Criteria for successful finish of testing could be changed but at first we can follow the general rules: </p><ul><li>There are no active defects of Blocker, Critical priorities </li><li>All new functionality is fully tested and verified.</li></ul><p>More information about this approach is described by Anton Sokolov. </p></div>
</div>
</div>
</div>