<p><br/></p><p>In testing scenario 1-5, observing credit limit at RBR and MRD.</p><p>Also, having not observed OTT/ATT full. The order of the performance degradation is as follow (until now)</p><ol><li>RBR/MRD credit first</li><li>Mesh congestion</li><li>Then OTT/ATT credit</li></ol><p>In this test, we will increase RBR/MRD size of the DCE and also decrease OTT size of the CAIUs.  DCE ATT size is already maximum size (64), and it was required to have full data at two CPU/two DMI scenario.</p><p><br/></p><p>By the way, have been told that credit will be shared resource from the 3.4. (01.19.2022)</p><p>No backpressure is being observed at ndn3 at mesh. </p><p>The empty pipe latency between DCE and DMI are as below (Updated ARTG)</p><ul><li>turn-around time of the MRD (MRD req valid ~ MRD rsp valid) : 16 cycles </li><li>turn-around time of the RBR (RBR req valid ~ RBR rsp valid) : 14 cycles </li></ul><p>The empty pipe latency between DCE and DMI are as below (Prev ARTG)</p><ul><li>turn-around time of the MRD (MRD req valid ~ MRD rsp valid) : 14 cycles </li><li>turn-around time of the RBR (RBR req valid ~ RBR rsp valid) : 12 cycles </li></ul><div class="table-wrap"><table class="relative-table wrapped confluenceTable" style="width: 83.7621%;"><colgroup><col style="width: 8.45266%;"/><col style="width: 10.3731%;"/><col style="width: 10.4684%;"/><col style="width: 9.70071%;"/><col style="width: 12.6756%;"/><col style="width: 48.2889%;"/></colgroup><tbody><tr><th class="confluenceTh"><br/></th><th class="confluenceTh">OTT (CAIU)</th><th class="confluenceTh">MRD (DCE)</th><th class="confluenceTh">RBR (DCE)</th><th colspan="1" class="confluenceTh">SNP (DCE)</th><th colspan="1" class="confluenceTh"><br/></th></tr><tr><td class="confluenceTd">~ 2022.01.18</td><td class="confluenceTd">96</td><td class="confluenceTd">6</td><td class="confluenceTd">8</td><td colspan="1" class="confluenceTd">4</td><td colspan="1" class="confluenceTd"><br/></td></tr><tr><td class="confluenceTd">2022.01.19</td><td class="confluenceTd"><p>64</p><p>The max OTT occupation at Sce 1.5 is 35.17</p></td><td class="confluenceTd"><p>9</p><p>Increasing 50%</p></td><td class="confluenceTd"><p>12</p><p>Increasing 50%</p></td><td colspan="1" class="confluenceTd">It will be updated later after observing numbers. Expecting relatively large increase</td><td colspan="1" class="confluenceTd"><p>Read miss case shows 80% Bandwidth. Expected value.</p><p>Read hit cases cannot be 100% because of the MRD credit. (showing 85%)</p><p>Write hit case cannot be 100% because of the RBR credit. (showing 55%)</p><p>==&gt; NDN3 does not have any credit issue. Purely loaded latency issue... <img class="emoticon emoticon-sad" data-emoji-id="1f641" data-emoji-shortname=":slight_frown:" data-emoji-fallback="🙁" src="https://arterisip.atlassian.net/wiki/s/-672721829/6452/d621ad2a33e27b90ca05c475b216bfab745e08a2/_/images/icons/emoticons/sad.png" width="16" height="16" data-emoticon-name="sad" alt="(sad)" /></p></td></tr><tr><td colspan="1" class="confluenceTd">2022.01.19</td><td colspan="1" class="confluenceTd">64</td><td colspan="1" class="confluenceTd">12</td><td colspan="1" class="confluenceTd">12</td><td colspan="1" class="confluenceTd">-</td><td colspan="1" class="confluenceTd"><p>Read miss: 80% (DCE ATT size)</p><p>Read hit : 86~87% .... still have credit limit</p><p>Write shows same results with the above.... </p><p>Stopped at here. If we start mix snoop, 87% looks enough.</p></td></tr><tr><td colspan="1" class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td><td colspan="1" class="confluenceTd"><br/></td></tr></tbody></table></div>