<p><strong>Intent for the week:</strong> </p><ul><li><p>Resolve recycle failed RTL/DV issue</p></li><li><p><del>Plot DMI scoreboard and look at what structural enhancements it could benefit from</del></p></li></ul><h2 id="Ncore3.6DMI:Week#02:1/8/24to1/12/24-Activities:"><strong>Activities:</strong></h2><ol start="1"><li><p><strong>General:</strong></p><ol start="1"><li><p>UVM cleanup</p><ol start="1"><li><p>

    

            



<style>
    .jira-issue {
        padding: 0 0 0 2px;
        line-height: 20px;
    }

    .jira-issue img {
        padding-right: 5px;
    }
    .jira-issue .aui-lozenge {
        line-height: 18px;
        vertical-align: top;
    }

    .jira-issue .icon {
        background-position: left center;
        background-repeat: no-repeat;
        display: inline-block;
        font-size: 0;
        max-height: 16px;
        text-align: left;
        text-indent: -9999em;
        vertical-align: text-bottom;
    }
</style>

    <span class="confluence-jim-macro jira-issue" data-jira-key="CONC-13525" >
                <a href="https://arterisip.atlassian.net/browse/CONC-13525?src=confmacro" class="jira-issue-key">CONC-13525</a>
                            </span>
 </p></li></ol></li><li><p>Update from last week: Made some changes in the scoreboard to pick up this scenario but hitting a read before write ordering issue, debugging this but no solution yet. </p><ol start="1"><li><p>RTL bug fix needs DV modeling. It’s a bit challenging to figure out this specific corner case. The gist is that when a nack_ce gets asserted in p2 all transactions below which was recycled with a nack(intended to recycle again) was being dropped. Design is trying to fix this issue by recording this behavior as recycle failed so they can attempt to recycle the transaction again successfully. Still looking into this issue. Essentially there’s a new signal that needs modelling and DV needs to absorb the alteration of how transactions are recycled/replayed and processed when this situation happens</p></li><li><p>

    

            



<style>
    .jira-issue {
        padding: 0 0 0 2px;
        line-height: 20px;
    }

    .jira-issue img {
        padding-right: 5px;
    }
    .jira-issue .aui-lozenge {
        line-height: 18px;
        vertical-align: top;
    }

    .jira-issue .icon {
        background-position: left center;
        background-repeat: no-repeat;
        display: inline-block;
        font-size: 0;
        max-height: 16px;
        text-align: left;
        text-indent: -9999em;
        vertical-align: text-bottom;
    }
</style>

    <span class="confluence-jim-macro jira-issue" data-jira-key="CONC-13554" >
                <a href="https://arterisip.atlassian.net/browse/CONC-13554?src=confmacro" class="jira-issue-key">CONC-13554</a>
                            </span>
</p></li></ol></li><li><p>XPROP failures: Synced up with Eric and Ben and clarified that this is a simulator only issue native to questa. This is specific to the memory model designed for DV usage, the aspect of using always(*) blocks causing contention in events scheduled that is leading to how the write to the cache is sampling the data from the previous cycle which causes it to read incorrect values. Need to get in touch with an AE to check if there is a simulator option to get past this error</p><ol start="1"><li><p>

    

            



<style>
    .jira-issue {
        padding: 0 0 0 2px;
        line-height: 20px;
    }

    .jira-issue img {
        padding-right: 5px;
    }
    .jira-issue .aui-lozenge {
        line-height: 18px;
        vertical-align: top;
    }

    .jira-issue .icon {
        background-position: left center;
        background-repeat: no-repeat;
        display: inline-block;
        font-size: 0;
        max-height: 16px;
        text-align: left;
        text-indent: -9999em;
        vertical-align: text-bottom;
    }
</style>

    <span class="confluence-jim-macro jira-issue" data-jira-key="CONC-13515" >
                <a href="https://arterisip.atlassian.net/browse/CONC-13515?src=confmacro" class="jira-issue-key">CONC-13515</a>
                            </span>
 </p></li></ol></li></ol></li><li><p><strong>Regression</strong>:</p><ol start="1"><li><p>3.6 Synopsys VIP+VCS regression (Not enabled in main regression):</p><ol start="1"><li><p>98% pass rate on 1 iteration</p></li></ol></li><li><p>3.6 Latest:</p><ol start="1"><li><p>Last stable regression didn’t pick RTL fix for 

    

            



<style>
    .jira-issue {
        padding: 0 0 0 2px;
        line-height: 20px;
    }

    .jira-issue img {
        padding-right: 5px;
    }
    .jira-issue .aui-lozenge {
        line-height: 18px;
        vertical-align: top;
    }

    .jira-issue .icon {
        background-position: left center;
        background-repeat: no-repeat;
        display: inline-block;
        font-size: 0;
        max-height: 16px;
        text-align: left;
        text-indent: -9999em;
        vertical-align: text-bottom;
    }
</style>

    <span class="confluence-jim-macro jira-issue" data-jira-key="CONC-13604" >
                <a href="https://arterisip.atlassian.net/browse/CONC-13604?src=confmacro" class="jira-issue-key">CONC-13604</a>
                            </span>
 </p></li><li><p>No successful regression last week due to long jenkins wait time. Have one currently dispatched and running jobs.</p></li></ol></li></ol></li></ol>