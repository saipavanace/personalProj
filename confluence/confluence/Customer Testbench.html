<style type='text/css'>/*<![CDATA[*/
div.rbtoc1759725297233 {padding: 0px;}
div.rbtoc1759725297233 ul {list-style: disc;margin-left: 0px;}
div.rbtoc1759725297233 li {margin-left: 0px;padding-left: 0px;}

/*]]>*/</style><div class='toc-macro rbtoc1759725297233'>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-1.Introduction'>1. Introduction</a></li>
<li><a href='#CustomerTestbench-2.DirectoryStructure'>2. Directory Structure</a></li>
<li><a href='#CustomerTestbench-3.DirectoryStructureforCustomer'>3. Directory Structure for Customer</a></li>
<li><a href='#CustomerTestbench-4.ArchitectureDiagram'>4. Architecture Diagram</a></li>
<li><a href='#CustomerTestbench-5.Maestro-CustomerTBFlow(Existing)'>5. Maestro - Customer TB Flow (Existing)</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-5.1MaestroFlow'>5.1 Maestro Flow</a></li>
<li><a href='#CustomerTestbench-5.2Runsimflow'>5.2 Runsim flow</a></li>
<li><a href='#CustomerTestbench-5.3ConfigCreationSteps'>5.3 Config Creation Steps</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-5.3.1UsingMaestroGUI'>5.3.1 Using Maestro GUI</a></li>
<li><a href='#CustomerTestbench-5.3.2UsingRandomizer'>5.3.2 Using Randomizer</a></li>
<li><a href='#CustomerTestbench-5.3.2UsingexistingMPFfile'>5.3.2 Using existing MPF file</a></li>
<li><a href='#CustomerTestbench-5.3.4Manual(inTCL)'>5.3.4 Manual (in TCL)</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-5.1Maestro-CustomerTBFlow(Proposed):'>5.1 Maestro - Customer TB Flow (Proposed):</a></li>
<li><a href='#CustomerTestbench-5.2DirectoryGenerationFlow(Proposed):'>5.2 Directory Generation Flow (Proposed):</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-7.RegressionStatus'>7. Regression Status</a></li>
<li><a href='#CustomerTestbench-8.TestBenchStructure'>8. Test Bench Structure</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-8.1TBTop'>8.1 TB Top</a></li>
<li><a href='#CustomerTestbench-8.2VIPConfigurationFile'>8.2 VIP Configuration File</a></li>
<li><a href='#CustomerTestbench-8.3Environment'>8.3 Environment</a></li>
<li><a href='#CustomerTestbench-8.4BootSequence'>8.4 Boot Sequence</a></li>
<li><a href='#CustomerTestbench-8.5CSRAccess'>8.5 CSR Access</a></li>
<li><a href='#CustomerTestbench-8.6BaseSequence'>8.6 Base Sequence</a></li>
<li><a href='#CustomerTestbench-8.7BaseVirtualSequence'>8.7 Base Virtual Sequence</a></li>
<li><a href='#CustomerTestbench-8.8BaseTest'>8.8 Base Test</a></li>
<li><a href='#CustomerTestbench-8.9Tests'>8.9 Tests</a></li>
<li><a href='#CustomerTestbench-8.10AddressManager'>8.10 Address Manager</a></li>
<li><a href='#CustomerTestbench-8.11VIPSequences'>8.11 VIP Sequences</a></li>
<li><a href='#CustomerTestbench-8.12FSYSScoreboard'>8.12 FSYS Scoreboard</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-9.Runningatest'>9. Running a test</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-9.1UsingMakeFile'>9.1 Using Make File</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-9.1.1MaestroGUI'>9.1.1 Maestro GUI</a></li>
<li><a href='#CustomerTestbench-9.1.2GeneratedTBfolder'>9.1.2 Generated TB folder</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-9.2UsingRunsim'>9.2 Using Runsim</a></li>
<li><a href='#CustomerTestbench-9.3ReproducingcustomerIssue'>9.3 Reproducing customer Issue</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-10.SupportedVIPandSimulators'>10. Supported VIP and Simulators</a>
<ul class='toc-indentation'>
<li><a href='#CustomerTestbench-10.1Cadence(Xcelium)notes'>10.1 Cadence (Xcelium) notes</a></li>
</ul>
</li>
<li><a href='#CustomerTestbench-11.TODO'>11. TODO</a></li>
<li><a href='#CustomerTestbench-12.FutureImprovements'>12. Future Improvements</a></li>
</ul>
</div><h1 id="CustomerTestbench-1.Introduction">1. Introduction</h1><p>This page aims to document the current customer testbench structure but I will try to include proposed improvements by making a note of it wherever possible</p><h1 id="CustomerTestbench-2.DirectoryStructure">2. Directory Structure</h1><p>|-- “cust_tb“</p><p>|--|-- “env“</p><p>|--|-- “tb“</p><p>|--|-- “tests”</p><h1 id="CustomerTestbench-3.DirectoryStructureforCustomer">3. Directory Structure for Customer</h1><p style="margin-left: 30.0px;">&lt;TBD&gt; Currently all files are dumped in the same folder. Here is a Jira ticket that aims to improve this: <a class="external-link" href="https://arterisip.atlassian.net/browse/MAES-6815" rel="nofollow">MAES-6815</a></p><h1 id="CustomerTestbench-4.ArchitectureDiagram">4. Architecture Diagram</h1><p>NOTE: FSYS Scoreboard and the SMI Monitors are not present in the customer TB as of today. </p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20240208-190311.png" width="915" src="https://arterisip.atlassian.net/wiki/download/attachments/417628298/image-20240208-190311.png?api=v2"></span><p /><h1 id="CustomerTestbench-5.Maestro-CustomerTBFlow(Existing)">5. Maestro - Customer TB Flow (Existing)</h1><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20240203-210003.png" width="915" src="https://arterisip.atlassian.net/wiki/download/attachments/417628298/image-20240203-210003.png?api=v2"></span><h2 id="CustomerTestbench-5.1MaestroFlow">5.1 Maestro Flow</h2><ul><li><p>The user configured Maestro GUI to configure the design</p></li><li><p>Towards the end of this process, Maestro dumps RTL and DV files</p></li><li><p>The DV files that are specified in the custTb.json file in dv/cust_tb/tb/ and the RTL files are pulled into Maestro on every Maestro build</p></li><li><p>Maestro will also generate an MPF binary file (which has the configuration information) and optionally a TCL file</p></li><li><p>We can go to the dv folder in Maestro output located at exe/output/tb/VCS/ , and run a specific testcase using the Makefile. The Makefile is also generated by Maestro (how? Need to check)</p></li><li><p>This is mainly how the customer runs the customer Testbench</p></li></ul><h2 id="CustomerTestbench-5.2Runsimflow">5.2 Runsim flow</h2><ul><li><p>We can use the MPF file generated by Maestro in the above step and write a TCL file to source the MPF or use the TCL file generated by Maestro directly or we can also handwrite TCL to create a config</p></li><li><p>The TCL source file in the above step will be added to the “runsim_testlist.json“ file in “non-customer Testbenches“ which can then be picked up by Runsim.</p></li><li><p>When we launch a test using runsim, the script invokes Maestro under the hood with the TCL added in above step as the source.</p></li><li><p>At this point, Maestro generates the RTL and the customer TB files just like in Maestro flow</p></li><li><p>Then, runsim invokes the buildTb script, which construct the DV files specific to the unit in which the test is run. For example, if the unit is CHI, build TB constructs CHI related DV files where CHI block will be the DUT (instead of entire NCORE).</p></li><li><p>Then runsim runs the simulation on the generated DV files (by build TB script) and generated RTL (by Maestro) and the simulations on them</p></li></ul><p>NOTE: we can enter the command “runsim -exe -h“ to get the table of steps involved in runsim</p><h2 id="CustomerTestbench-5.3ConfigCreationSteps">5.3 Config Creation Steps</h2><h3 id="CustomerTestbench-5.3.1UsingMaestroGUI">5.3.1 Using Maestro GUI</h3><p>Detailed explanation of step by step process to construct a config in Maestro is provided <a href="https://arterisip.atlassian.net/wiki/spaces/ENGR/pages/757792866/Ncore+Parameters" data-linked-resource-id="757792866" data-linked-resource-version="5" data-linked-resource-type="page">here</a></p><h3 id="CustomerTestbench-5.3.2UsingRandomizer">5.3.2 Using Randomizer</h3><p>TBD</p><h3 id="CustomerTestbench-5.3.2UsingexistingMPFfile">5.3.2 Using existing MPF file</h3><h3 id="CustomerTestbench-5.3.4Manual(inTCL)">5.3.4 Manual (in TCL)</h3><h2 id="CustomerTestbench-5.1Maestro-CustomerTBFlow(Proposed):">5.1 Maestro - Customer TB Flow (Proposed):</h2><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20240207-054940.png" width="622" src="https://arterisip.atlassian.net/wiki/download/attachments/417628298/image-20240207-054940.png?api=v2"></span><ul><li><p>The existing flow has couple of problems</p><ul><li><p>There are redundant DV files that are generated, once by Maestro and once by the “buildTB“ script within the “runsim“ script. It is lot cleaner just to have a single copy of generated DV</p></li><li><p>We always run regressions on the RTL, with the DV generated by “buildTB” script but we ship the DV generated by Maestro. For whatever reason, if the DV generated by buildTB script is different from the DV generated by Maestro, we risk shipping untested code</p></li></ul></li><li><p>Hence, to overcome these issues, we can skip the “buildTB” part of runsim and point to the files generated by Maestro to run any simulations</p></li><li><p>This way we guarantee that we always run our simulations on the files generated by Maestro and be consistent with it</p></li><li><p>Since we are using Maestro to generate the Makefile in this scenario, the Makefile can be generated with any config that we have (or add) in our runsim_testlist. That way, in case we are the first one’s to identify any issue with customer TB, and if the AE wants to run it on their side, we can just point them to the DV folder that was generated using runsim flow and they can just use the Makefile to run any simulations.</p></li></ul><h2 id="CustomerTestbench-5.2DirectoryGenerationFlow(Proposed):">5.2 Directory Generation Flow (Proposed):</h2><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20240218-210950.png" width="813" src="https://arterisip.atlassian.net/wiki/download/attachments/417628298/image-20240218-210950.png?api=v2"></span><p /><ul><li><p>If Maestro can capture the user intent of whether the required TB is of type Synopsys or Cadnece, this switch can be passed to the build TB script which can generate the appropriate TB files (This requires an update to Maestro)</p></li><li><p>Based on this switch, we can also generate the register model directly to customer instead of putting the burden on them to run other tools (still need to discuss if we want to user CSRCompiler or not)</p></li><li><p>This also helps organize our customer TB directories by maintaining 2 separate directories for SNPS and Cadence, with a directory to hold all common files</p></li><li><p>Finally we can read this directory structure from our buildTB script and can force it to dump the directories in a similar fashion to give it to our customer solving the issue mentioned in <a class="external-link" href="https://arterisip.atlassian.net/browse/MAES-6815" rel="nofollow">this</a> ticket</p></li></ul><h1 id="CustomerTestbench-7.RegressionStatus">7. Regression Status</h1><p>TBD</p><h1 id="CustomerTestbench-8.TestBenchStructure">8. Test Bench Structure</h1><h2 id="CustomerTestbench-8.1TBTop">8.1 TB Top</h2><ul><li><p>This file is the interface between the RTL and DV. We instantiate Ncore chip (DUT) and make the necessary connections between inputs and outputs of the DUT to the wires in the interface</p></li><li><p>The UVM packages are imported in this file along with the inclusion of required testcases</p></li><li><p>All required interfaces are also instantiated at this level and these are set into the UVM configDB for later retrieval from Monitors, Drivers etc.</p></li></ul><h2 id="CustomerTestbench-8.2VIPConfigurationFile">8.2 VIP Configuration File</h2><p>This is the main file in which we control and configure the VIP to describe our design for proper stimulus. For example address width, data size, supported features, type of interface etc.</p><h2 id="CustomerTestbench-8.3Environment">8.3 Environment</h2><p>This is the file in which we do following important tasks</p><ul><li><p>Instantiate and create register model</p></li><li><p>Instantiate and create VIP environments and set them to config DB for use by the VIPs</p></li><li><p>Instantiate and create VIP configuration object and set them to config DB for use by the VIPs</p></li></ul><p>NOTE: This file currently does necessary overrides of VIP classes with our custom classes. However, it is better we move this to the base test to later child tests modify the overrides</p><h2 id="CustomerTestbench-8.4BootSequence">8.4 Boot Sequence</h2><p>This sequence drives necessary stimulus to configure/bringup Ncore before we can drive any traffic into the system.</p><p>NOTE: Required tasks to boot NCORE are specified comprehensively in <a href="https://arterisip.atlassian.net/wiki/spaces/ENGR/pages/444301322/NCORE+System+Booting" data-linked-resource-id="444301322" data-linked-resource-version="7" data-linked-resource-type="page">this </a>page</p><h2 id="CustomerTestbench-8.5CSRAccess">8.5 CSR Access</h2><p>The register model is instantiated in the environment and this model is used to read and write to the registers</p><p>NOTE: We did not implement the complete UVM REG MODEL, especially the predictor and register mirroring. This will be a future enhancement</p><h2 id="CustomerTestbench-8.6BaseSequence">8.6 Base Sequence</h2><p>The base sequence has 2 important functions:</p><ul><li><p>Instantiate a register model to which the we pass the handle to the register model instantiated in the environment. This allows us to access registers in sequences</p></li><li><p>Implement all the common functions that the child sequences commonly need to drive stimulus. Basically all common logic in all sequences should go into this class</p></li></ul><h2 id="CustomerTestbench-8.7BaseVirtualSequence">8.7 Base Virtual Sequence</h2><p>Base virtual sequence is started in the base test and it in turn starts the base sequence</p><h2 id="CustomerTestbench-8.8BaseTest">8.8 Base Test</h2><p>The base test has the following functions:</p><ul><li><p>Instantiate and build the environment</p></li><li><p>Construct general functions like report server, timeout catcher etc</p></li><li><p>Create and start the boot sequence</p></li></ul><h2 id="CustomerTestbench-8.9Tests">8.9 Tests</h2><p>Each test (which extends from the base test) exercises a single and specific scenario by calling a virtual sequence or sequence which generates a particular stimulus</p><p>NOTE: Currently all tests coded in a single file. For maintenance and debuggability reasons, it is better to have a single test in a single file starting a single sequence.</p><h2 id="CustomerTestbench-8.10AddressManager">8.10 Address Manager</h2><h2 id="CustomerTestbench-8.11VIPSequences">8.11 VIP Sequences</h2><h2 id="CustomerTestbench-8.12FSYSScoreboard">8.12 FSYS Scoreboard</h2><h1 id="CustomerTestbench-9.Runningatest">9. Running a test</h1><h2 id="CustomerTestbench-9.1UsingMakeFile">9.1 Using Make File</h2><p>There are 2 ways we can run a customer Testbench test using the Make file</p><h3 id="CustomerTestbench-9.1.1MaestroGUI">9.1.1 Maestro GUI</h3><h3 id="CustomerTestbench-9.1.2GeneratedTBfolder">9.1.2 Generated TB folder</h3><ul><li><p>We always have a generated stand-alone testbench dumped under the 'exe' at output $WORK_TOP/debug/exe/output/tb/VCS path.</p></li><li><p>There is also a Makefile dumped in that path and this make file can be used independently to run a testcase. </p></li><li><p>However, we need to setup a couple of environment variables (this is as of current setup. Need to check if this can be cleaned up)</p><ul><li><p>setenv PROJ_HOME &lt;path to the output directory&gt;   (for example, in the path mentioned above, it is setenv PROJ_HOME $WORK_TOP/debug/exe/output)</p></li><li><p>setenv SNPS_AMBA_VIP /engr/dev/tools/synopsys/2020.12_amba_vip</p></li></ul></li></ul><h2 id="CustomerTestbench-9.2UsingRunsim">9.2 Using Runsim</h2><ul><li><p>Using runsim flow for customer TB is same like any other testbench. Here is the general command to run the test: <strong>runsim -e cust_tb -c &lt;config_name&gt; -t &lt;test name&gt;</strong></p></li></ul><h2 id="CustomerTestbench-9.3ReproducingcustomerIssue">9.3 Reproducing customer Issue</h2><p>We need to take the following steps to reproduce a customer issue using runsim flow</p><ul><li><p>We need to get the customer config in some format, either in TCL or MPF</p></li><li><p>Then we create a directory under $WORK_TOP/../hw-test-projects/&lt;proj_name&gt;_configs/base_configs with an appropriate name and copy the config given to us into that directory</p></li><li><p>If we get a TCL config, we can add that to runsim file directly, but if we get a MPF file, we need to convert it to TCL (just source that in a TCL file) and use that TCL in runsim instead</p></li><li><p>Once we add the TCL file in runsim, we have the configs available in the runsim flow, then we can add tests and run as normal</p></li></ul><h1 id="CustomerTestbench-10.SupportedVIPandSimulators">10. Supported VIP and Simulators</h1><p>Currently we only support the below combinations. We will support more in the future with Cadence/Xcelium being the next one.</p><span class="confluence-embedded-file-wrapper image-left-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-left" alt="image-20240207-062739.png" width="309" src="https://arterisip.atlassian.net/wiki/download/attachments/417628298/image-20240207-062739.png?api=v2"></span><h2 id="CustomerTestbench-10.1Cadence(Xcelium)notes">10.1 Cadence (Xcelium) notes</h2><ul><li><p>Set up the license file and path.  Note that the “:$LM_LICENSE_FILE” isn’t necessary if only cadence verification tools are used, VIP may have a different license server</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">export LM_LICENSE_FILE=5282@lic01.arteris.com:$LM_LICENSE_FILE
export PATH=$PATH:/engr/dev/tools/cadence/XCELIUM_23.03.001/bin:/engr/dev/tools/cadence/XCELIUM_23.03.001/tools/xcelium/bin:/engr/dev/tools/cadence/XCELIUM_23.03.001/tools.lnx86/bin/</pre>
</div></div></li><li><p>registers</p><ul><li><p>download ARM/AMBA bus definitions in IPXACT form from <a class="external-link" href="https://developer.arm.com/Architectures/AMBA#Software-Download" rel="nofollow">AMBA (arm.com)</a> and then unzip to a directory.  That is used in -incdir below</p></li><li><p>command to generate uvm_regs:</p><div class="code panel pdl" style="border-width: 1px;"><div class="codeContent panelContent pdl">
<pre class="syntaxhighlighter-pre" data-syntaxhighlighter-params="brush: java; gutter: false; theme: Confluence" data-theme="Confluence">reg_verifier -dut_name &lt;config_name&gt; -top &lt;config&gt;_2009.xml -incdir &lt;/path/to/&gt;AR500-DA-10037-r1p3-00rel0/ipxact2009/ -domain uvmreg -no_uvm_factory -out_dir &lt;/path/to/outdir&gt;</pre>
</div></div><p>note that -out_dir is optional.  If not used then the /path/to/outdir is $CWD/reg_verifier_dir</p></li><li><p>Output is in &lt;/path/to/outdir/&gt;uvmreg, the important files are cdns_uvmreg_rdb.sv and cdns_uvmreg_utils_pkg.sv</p></li><li><p>registers are named:  model.&lt;memory_map&gt;_&lt;address_block&gt;.&lt;REGNAME&gt;<br/>for example:  model.ncore_caiu0.CAIUIDR. or model.ncore_sys_global_register_blk.GRBUCSSFIDR0</p></li></ul></li></ul><h1 id="CustomerTestbench-11.TODO">11. TODO</h1><ul><li><p>Add an object which collects all json parameters and converts them into system verilog world</p></li></ul><h1 id="CustomerTestbench-12.FutureImprovements">12. Future Improvements</h1><ul><li><p>Need a testbench configuration object to configure entire Testbench</p></li><li><p>Need a file/object to hold all json parameters and convert them into system verilog parameters so that our test-bench is mostly in native system verilog</p></li><li><p>More improvement tasks are tracked in <a class="external-link" href="https://arterisip.atlassian.net/browse/CONC-13640" rel="nofollow">this</a> epic</p></li></ul><p />